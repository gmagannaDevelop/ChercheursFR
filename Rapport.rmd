---
title: "Rapport Projet Statistique multidimensionnelle - Groupe 2"
author: "Gustavo MAGAÑA LÓPEZ, Simon MATTENS, Joachim SNEESSENS"
date: "11 juin 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Introduction
Ce projet est constitué de deux questions. La première consiste à produire l'analyse et le commentaire du fichier de données et la deuxième à décrire une méthode d'analyse non vue au cours. 

Pour ce faire, nous avons utilisé le logiciel R. 


## Question 1 
Le fichier a analyser est le fichier "pourcentage_chercheurs_france.xslx".

Chaque case spécifie la proportion de chercheurs dans la région spécifiée par la ligne pour une certaine année spécifiée par la colonne.
Le but était d'effectuer une analyse en composantes principales des données, de dire si le profil est stable dans le temps et enfin de dégager des groupements de régions en fonction de leur comportement à l'aide d'une classification hiérarchique acendante.

### ACP
Le but de l'ACP est de réduire la dimension des données initiales (ici 8 car 8 années différentes) en remplaçant ces 8 variables initiales par n facteurs appropriés (avec n < 8).
Avant de commencer l'ACP nous avons retiré la première colonne contenant les noms des différentes régions de France.
Ci-dessous un boxplot des données non centrées non réduites.

```{r somePlot, echo=FALSE, message=FALSE}

library(ade4)
library(xlsx)
library(factoextra)
library(dplyr)
library(FactoMineR)
library(corrplot)

clean.names <- function(x){
  strsplit(x, 
           split = "(",
           fixed = TRUE)[[1]][[1]]
}

dataSet <- read.xlsx("data.xlsx",sheetIndex=1)

# Construction de la matrice (DataFrame) :
chercheurs <- dataSet
row.names(chercheurs) <- chercheurs$geo.time
row.names(chercheurs) <- unlist(lapply(row.names(chercheurs), clean.names))
chercheurs <- subset(chercheurs, select = -c(geo.time))

chercheurs.scaled <- scale(chercheurs)

# Effet de la transformation sur la distribution des donnees :
boxplot(chercheurs, main = "Avant centrage des données")
```

Après avoir effectué un centrage et une réduction des données, voici que donne le boxplot.

```{r centrage, echo=FALSE, message=FALSE}
boxplot(chercheurs.scaled, main = "Après centrage des données")
```
\vspace{12pt}

Nous pouvons remarquer que pour chaque année, les médianes sont inférieures aux moyennes ce qui signifie que la répartition est assez déséquilibrée. Néanmoins nous constatons que ce déséquilibre se retrouve pour chacune de ces variables, ces dernières ont des distributions relativement similaires.


```{r valeursPropres, echo=FALSE, message=FALSE}
chercheurs.corr <- cor(chercheurs.scaled)
ch.fr.scaled.cor.eigen <- eigen(chercheurs.corr)
ch.fr.scaled.inertia <- ch.fr.scaled.cor.eigen$values / sum(ch.fr.scaled.cor.eigen$values)
barplot(ch.fr.scaled.cor.eigen$values, main = "Valeurs propres")
ch.fr.scaled.inertia
```

Cette étape a consisté dans un premier temps à calculer la matrice des corrélations de la matrice centrée-réduite pour dans un second temps en calculer les valeurs propres.
Vu l'allure des valeurs propres nous allons garder deux axes comme la visualisation ne peut pas se faire correctement si on ne garde qu'un seul axe.

### Cercle des corrélations
```{r corrcircle, echo=FALSE, message=FALSE, fig.align="center", fig.width=5, fig.height=2.5}
ch.fr.pca <- dudi.pca(chercheurs, scann=FALSE, nf = 2)
s.corcircle(ch.fr.pca$co)
```
\vspace{5pt}

Grâce au cercle de corrélations, nous pouvons voir que toutes les variables (années) 
ont une forte corrélation les unes avec les autres. Nous savons aussi que elles sont 
négativement corrélées avec la première composante principale et elles sont bien représentées 
sur celle-ci. Quelques-unes sont négativement corrélées avec la deuxième composante principale, 
autres le sont positivement cependant la corrélation est très faible pour toutes.

### ACP : Représentations complémentaires
```{r qualiteRep, echo=FALSE, message=FALSE, fig.align="center"}
fviz_pca_ind(
  ch.fr.pca,
  col.ind = "cos2", # Color by the quality of representation
  gradient.cols = rainbow(10),
  repel = TRUE     # Avoid text overlapping
)
```
\vspace{3pt}

Visualisation de l'ACP où l'on trouve que les individus sont des points colorés 
en fonction de la valeur du cosinus carré, c'est-á-dire la qualité de leur représentation dans l'ACP.

```{r biplot1, echo=FALSE, message=FALSE}
# On peut voir les vecteurs des anciennes variables sur les composants principaux.
fviz_pca_biplot(
  ch.fr.pca,
  repel = TRUE,
  col.var = "#2E9FDF", # Variables color
  col.ind = "#696969"  # Individuals color
)
```

Le biplot nous permet d'avoir la représentation simultanée des variables et individus que l'on
a utilisés pour l'ACP. Dans un biplot, la direction des vecteurs correspodants aux variables
nous permet de voir à grosso modo la corrélation que chaque variable a avec chaque composante principale.
D'après le biplot, toutes les variables sont forte et négativement corrélées avec la première composante principale
et faiblement corrélées avec la deuxième. Si à ce fait on ajoute la variation minimale expliquée par celle-ci, 
nous avons que plus les régions sont à gauche dans le biplot, plus haute est la valeur qu'elles ont prise 
pour toutes les années.

\newpage

## Stabilité temporelle du profil

Pour faire cette partie de l'analyse nous avons utilisé plusieurs outils. 
Au premier instant, la matrice de corrélation nous permet de voir s'il existe ou pas de corrélation entre chaque couple de variables. 
Au moyen de la fonction **corrplot()** ce que l'on a est une matrice contenant des cercles colorés et une échelle de telle façon qu'il suffit un coup d'oeil pour avoir une vision générale des corrélations.
Si l'on pense, chaque colonne que l'on a prise comme variable n'est autre qu'un vecteur contenant la valeur
que chaque région a obtenue pour une année spécifique : le profil de l'année. 
S'il existe une corrélation positive assez forte parmi les colonnes ça veut dire que le profil, 
c'est-à-dire la rélation entre régions, est stable dans le temps. 

```{r profilStable, echo=TRUE, message=FALSE, out.width='.42\\linewidth', fig.align='center'}
chercheurs.corr <- cor(chercheurs.scaled)
corrplot(chercheurs.corr, type="upper")
```
Ces corrélations nous montrent que **le profil est stable dans le temps**. Pour justifier ce raisonement il suffit de penser au cas contraire : Un profil qui n'est pas stable dans le temps.
Disons que nous avons deux années où une région a augmenté ou diminué d'une façon différente aux autres. 
La matrice de corrélations ne ressemblerait plus à celle que l'on a dans la figure précédente. 
Pour simuler cette situation, nous créons un **corrplot** avec la matrice que l'on avait plus un peu de bruit.
```{r profilPasStable, echo=TRUE, message=FALSE, out.width='.42\\linewidth', fig.align='center'}
foo <- apply(chercheurs, 2, function(x){ x + rnorm(n = length(x), mean = 1, sd = 0.3) })
foo.scaled <- scale(foo)
corrplot(cor(foo.scaled), type="upper")
```
\newpage

Nous pouvons également ajouter à la justification de notre affirmation de la stabilité temporelle 
du profil l'analyse des contributions des variables aux composantes principales. 
Il faut premièrement rappeler ce que l'on avait obtenu grâce au ACP : Deux composantes représentant 
le 99,5% et 0,2% de la variation totale respectivement. Nous présentons les contributions des variables 
à chacune des composantes principales. Il faut tenir en compte que ce qui se passe sur la deuxième 
composante principale n'est pas très significatif donné qu'elle ne représente que le 0,2% de la variation.
\vspace{12pt}

Contributions des variables :
```{r contribVar, echo=FALSE, message=FALSE, out.width='.45\\linewidth', fig.width=3, fig.height=3}
fviz_contrib(ch.fr.pca, choice = "var", axes = 1, top = 10, title="Contributions à la 1ère CP") 
fviz_contrib(ch.fr.pca, choice = "var", axes = 2, top = 10, title="Contributions à la 2ème CP") 
```
\vspace{12pt}

Nous pouvons voir que chaque année contribue également à la première composante principale. 
Si le profil changeait considérablement pour un année, sa variation serait différente à celles des autres, 
ce qui nous donnerait une autre distribution. 

Pour justifier encore notre affirmation, nous affichons les variations temporelles pour chaque région (**var.regions**) 
et les variations régionales pour chaque année (**var.annees**). 
Ce que l'on voit c'est une variation beaucoup plus importante dans chaque année 
(ça veut dire que les régions sont bien différentes pour l'année) que dans chaque région (au fil du temps).

Analyse des variances :
```{r plot9, echo=TRUE, message=FALSE}
var.regions <- apply(chercheurs, 1, function(x){ var(as.numeric(x)) })
var.annees <- apply(chercheurs, 2, function(x){ var(as.numeric(x)) })
var.regions
var.annees
```

```{r hcpcArbre, echo=FALSE, message=FALSE}
# Classification hierarchique :
ch.fr.pca2 <- PCA(chercheurs.scaled, graph = FALSE)
ch.fr.hcpc <- HCPC(ch.fr.pca2, nb.clust = 3, graph = FALSE)
fviz_dend(ch.fr.hcpc,
          cex = 0.7,                     # Label size
          palette = "jco",               # Color palette see ?ggpubr::ggpar
          rect = TRUE, rect_fill = TRUE, # Add rectangle around groups
          rect_border = "jco",           # Rectangle color
          labels_track_height = 0.8      # Augment the room for labels
)
```
\vspace{12pt}

Holla

```{r hcpcClusters, echo=FALSE, message=FALSE}
fviz_cluster(ch.fr.hcpc,
             repel = TRUE,            # Avoid label overlapping
             show.clust.cent = TRUE, # Show cluster centers
             palette = "jco",         # Color palette see ?ggpubr::ggpar
             ggtheme = theme_minimal(),
             main = "Factor map"
)

```


